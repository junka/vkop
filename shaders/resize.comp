#version 450 core

layout(set=0, binding=0) writeonly uniform image2DArray uOutput;
layout(set=0, binding=1) uniform sampler2DArray uInput;


layout(push_constant) uniform resizeBuffer{
    ivec4 inShape;      // N, C, H_in, W_in
    ivec4 outShape;     // N, C, H_out, W_out
    int mode;
    int nearest_mode;
    int antialias;
    int coordinate_transformation_mode;
    float cubic_coeff_a;
} uResizeParam;

#define HALF_PIXEL 0
#define HALF_PIXEL_SYMMETRIC 1
#define PYTORCH_HALF_PIXEL 2
#define ALIGN_CORNERS 3
#define ASYMMETRIC 4
#define TF_CROP_AND_RESIZE 5

#define NEAREST 0
#define LINEAR 1
#define CUBIC 2

#define STRECH 0
#define NOT_LARGER 1
#define NOT_SMALLER 2

#define ROUND_PREFER_FLOOR 0
#define ROUND_PREFER_CEIL 1
#define FLOOR 2
#define CEIL 3

layout(local_size_x = 16, local_size_y = 16, local_size_z = 1) in;


vec2 transform_coordinate(float out_h, float out_w, float in_h, float in_w, int mode) {
    float oh = out_h;
    float ow = out_w;
    float ih = in_h;
    float iw = in_w;
    float ih_m1 = ih - 1.0;
    float iw_m1 = iw - 1.0;

    float in_y, in_x;

    if (mode == HALF_PIXEL) { // half_pixel
        //x_original = (x_resized + 0.5) / scale - 0.5
        if (uResizeParam.outShape.z > 1) {
            in_y = (oh + 0.5) * ih / float(uResizeParam.outShape.z) - 0.5;
        } else {
            in_y = 0.5 * ih_m1;
        }
        if (uResizeParam.outShape.w > 1) {
            in_x = (ow + 0.5) * iw / float(uResizeParam.outShape.w) - 0.5;
        } else {
            in_x = 0.5 * iw_m1;
        }
    } else if (mode == HALF_PIXEL_SYMMETRIC) { // half_pixel_symmetric, since v19
        // adjustment = output_width_int / output_width
        // center = input_width / 2
        // offset = center * (1 - adjustment)
        // x_ori = offset + (x + 0.5) / scale - 0.5
        float scale_h = max(ih / float(uResizeParam.outShape.z), 1.0);
        float scale_w = max(iw / float(uResizeParam.outShape.w), 1.0);
        in_y = (oh + 0.5) * scale_h - 0.5;
        in_x = (ow + 0.5) * scale_w - 0.5;
    } else if (mode == PYTORCH_HALF_PIXEL) { // pytorch_half_pixel
        //x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0
        if (uResizeParam.outShape.z > 1) {
            in_y = (oh + 0.5) * ih / float(uResizeParam.outShape.z) - 0.5;
        } else {
            in_y = 0.0;
        }
        if (uResizeParam.outShape.w > 1) {
            in_x = (ow + 0.5) * iw / float(uResizeParam.outShape.w) - 0.5;
        } else {
            in_x = 0.0;
        }
    }
    else if (mode == ALIGN_CORNERS) { // align_corners
        // x_original = x_resized * (length_original - 1) / (length_resized - 1)
        if (uResizeParam.outShape.z > 1) {
            in_y = oh * ih_m1 / (float(uResizeParam.outShape.z) - 1.0);
        } else {
            in_y = 0.0;
        }
        if (uResizeParam.outShape.w > 1) {
            in_x = ow * iw_m1 / (float(uResizeParam.outShape.w) - 1.0);
        } else {
            in_x = 0.0;
        }
    } else if (mode == ASYMMETRIC) { // asymmetric
        // x_original = x_resized / scale
        in_y = oh * ih / float(uResizeParam.outShape.z);
        in_x = ow * iw / float(uResizeParam.outShape.w);
    } else { // mode == 5: tf_crop_and_resize (not supported here)
        // x_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1)
        in_y = 0.0;
        in_x = 0.0;
    }

    return vec2(in_x, in_y);
}

// 双线性采样
vec4 sample_bilinear(sampler2DArray tex, vec2 uv, int layer, int in_w, int in_h_total) {
    uv = clamp(uv, vec2(0.0), vec2(float(in_w) - 1e-5, float(in_h_total) - 1e-5));
    ivec2 iuv = ivec2(uv);
    vec2 f = fract(uv);

    vec4 tl = texelFetch(tex, ivec3(iuv.x, iuv.y, layer), 0);
    vec4 tr = texelFetch(tex, ivec3(min(iuv.x + 1, in_w - 1), iuv.y, layer), 0);
    vec4 bl = texelFetch(tex, ivec3(iuv.x, min(iuv.y + 1, in_h_total - 1), layer), 0);
    vec4 br = texelFetch(tex, ivec3(min(iuv.x + 1, in_w - 1), min(iuv.y + 1, in_h_total - 1), layer), 0);

    vec4 top = mix(tl, tr, f.x);
    vec4 bot = mix(bl, br, f.x);
    return mix(top, bot, f.y);
}

vec4 sample_nearest(sampler2DArray tex, vec2 uv, int layer, int in_w, int in_h_total)
{
    vec4 value;
    ivec2 in_pixel;

    if (uResizeParam.nearest_mode == ROUND_PREFER_FLOOR) {
        // 0.5 -> 0: use floor(uv + 0.5 - eps)
        const float eps = 1e-5;
        in_pixel = ivec2(floor(uv + 0.5 - eps));
    } 
    else if (uResizeParam.nearest_mode == ROUND_PREFER_CEIL) {
        // 0.5 -> 1: use floor(uv + 0.5)
        in_pixel = ivec2(floor(uv + 0.5));
    } 
    else if (uResizeParam.nearest_mode == FLOOR) {
        in_pixel = ivec2(floor(uv));
    } 
    else { // CEIL
        in_pixel = ivec2(ceil(uv));
    }

    in_pixel.x = clamp(in_pixel.x, 0, in_w - 1);
    in_pixel.y = clamp(in_pixel.y, 0, in_h_total - 1);
    return value;
}

void main()
{
    ivec3 gid = ivec3(gl_GlobalInvocationID);
    int out_w = gid.x;
    int out_h_batch = gid.y;   // = n * H_out + h
    int c4 = gid.z;            // layer index = channel group

    int N = uResizeParam.outShape.x;
    int C = uResizeParam.outShape.y;
    int H_out = uResizeParam.outShape.z;
    int W_out = uResizeParam.outShape.w;
    int C4 = (C + 3) / 4;

    // Bounds check
    if (out_w >= W_out || out_h_batch >= N * H_out || c4 >= C4) {
        return;
    }

    int out_n = out_h_batch / H_out;
    int out_h = out_h_batch % H_out;

    // Input shape
    int H_in = uResizeParam.inShape.z;
    int W_in = uResizeParam.inShape.w;

    // Transform output (h,w) → input (h_in, w_in)
    vec2 in_uv = transform_coordinate(
        float(out_h), float(out_w),
        float(H_in), float(W_in),
        uResizeParam.coordinate_transformation_mode
    );

    // Compute full input y coordinate including batch
    float in_y_full = float(out_n * H_in) + in_uv.y;
    vec2 input_coord = vec2(in_uv.x, in_y_full);

    vec4 value;
    if (uResizeParam.mode == 1) { // bilinear
        value = sample_bilinear(uInput, input_coord, c4, W_in, N * H_in);
    } else {
        value = sample_nearest(uInput, input_coord, c4, W_in, N * H_in);
    }

    imageStore(uOutput, gid, value);
}

