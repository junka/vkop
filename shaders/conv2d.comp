// Prototype:
//  torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)
//
// onnx:Conv
//  inputs: input, weight, bias(optional)
//  attributes:
//      strides: list of ints
//      pads: list of ints
//      dilations: list of ints
//      group: int
//      auto_pad: string, default ""
//  output: output
//  input shape: (N, C_in, H_in, W_in)  (NCHW)
//  weight shape: (C_out, C_in/groups, kH, kW)
//  bias shape: (C_out)
//  output shape: (N, C_out, H_out, W_out)
//      H_out = floor((H_in + 2*padding[0] - dilation[0]*(kH-1) - 1)/strides[0] + 1
//      W_out = floor((W_in + 2*padding[1] - dilation[1]*(kW-1) - 1)/strides[1] + 1
#version 450 core

#ifdef FP16
#extension GL_AMD_gpu_shader_half_float: enable
#extension GL_EXT_shader_16bit_storage : enable
#extension GL_EXT_shader_explicit_arithmetic_types_float16 : enable
#define FLOAT float16_t
#define FLOAT4 f16vec4
#else
#define FLOAT float
#define FLOAT4 vec4
#endif

#include "activation.comp"

layout(local_size_x = 16, local_size_y = 16, local_size_z = 1) in;

layout(set=0, binding=0) writeonly uniform image2DArray uOutput;   // [W_out, N*H_out, C4_out]
layout(set=0, binding=1) uniform sampler2DArray uInput;            // [W_in, N*H_in, C4_in]
layout(set=0, binding=2) uniform sampler2DArray uKernel;           // [K_W , K_H * C_out, C4_in]
layout(set=0, binding=3) readonly buffer biasBuffer {
    FLOAT attr[]; // bias[C_out]
} uBias;

layout(push_constant) uniform constBuffer {
    ivec4 inputSize;     // [W_in, H_in, C_in, N]
    ivec4 outputSize;    // [W_out, H_out, C_out, N]
    ivec4 kernelSize;    // [K_W, K_H, unused, unused]
    ivec4 imageSize;     // [realW=W_out, realH=N*H_out, C4_out, 1]
    ivec2 stride;
    ivec2 padding;
    ivec2 dilation;
    int groups;
    int bias;
    int activation;
} uConstant;

void main() {
    ivec3 gid = ivec3(gl_GlobalInvocationID);
    int W_out = uConstant.outputSize.x;
    int realH = uConstant.imageSize.y;
    int C4_out = uConstant.imageSize.z;

    if (gid.x >= W_out || gid.y >= realH || gid.z >= C4_out) return;

    int H_out = uConstant.outputSize.y;
    int C_out = uConstant.outputSize.z;
    int N = uConstant.outputSize.w;

    int W_in = uConstant.inputSize.x;
    int H_in = uConstant.inputSize.y;
    int C_in = uConstant.inputSize.z;
    int G = uConstant.groups;

    // Decode spatial and channel
    int w = gid.x;
    int c4 = gid.z;
    int n = gid.y / H_out;
    int h = gid.y % H_out;

    // Output channel start
    int oc_start = c4 * 4;
    ivec4 oc_vec = oc_start + ivec4(0, 1, 2, 3);
    bvec4 valid_oc = lessThan(oc_vec, ivec4(C_out));

    // Compute input start position (with padding)
    ivec2 out_pos = ivec2(w, h);
    ivec2 s0 = out_pos * uConstant.stride - uConstant.padding;

    FLOAT4 acc = FLOAT4(0.0);

    int K_W = uConstant.kernelSize.x;
    int K_H = uConstant.kernelSize.y;
    int C_out_per_group = C_out / G;
    int C_in_per_group = C_in / G;

    // For each output channel in this vec4
    for (int comp = 0; comp < 4; ++comp) {
        if (!valid_oc[comp]) continue;

        int oc = oc_vec[comp];
        int g = oc / C_out_per_group; // which group?

        // Input channel range for this group
        int ic_start = g * C_in_per_group;
        int ic_end = ic_start + C_in_per_group;

        FLOAT sum = FLOAT(0.0);

        // Slide kernel
        for (int ky = 0; ky < K_H; ++ky) {
            int iy = s0.y + ky * uConstant.dilation.y;
            if (iy < 0 || iy >= H_in) continue;

            for (int kx = 0; kx < K_W; ++kx) {
                int ix = s0.x + kx * uConstant.dilation.x;
                if (ix < 0 || ix >= W_in) continue;

                // Iterate over input channels in this group
                for (int ic = ic_start; ic < ic_end; ++ic) {
                    int ic4 = ic / 4;
                    int ic_comp = ic % 4;

                    // Fetch input pixel
                    int in_y = n * H_in + iy;
                    FLOAT4 input_val = FLOAT4(texelFetch(uInput, ivec3(ix, in_y, ic4), 0));
                    FLOAT x = input_val[ic_comp];

                    // Compute kernel coordinate
                    int local_ic = ic - ic_start; // local within group
                    int local_ic4 = local_ic / 4;
                    int local_ic_comp = local_ic % 4;

                    int kx_k = kx;
                    int ky_k = ky + oc * K_H;
                    FLOAT4 weight_vec = texelFetch(uKernel, ivec3(kx_k, ky_k, local_ic4), 0);
                    FLOAT w = weight_vec[local_ic_comp];

                    sum += x * w;
                }
            }
        }
        acc[comp] = sum;
    }

    // Add bias
    if (uConstant.bias == 1) {
        FLOAT4 bias_val = FLOAT4(0.0);
        for (int i = 0; i < 4; ++i) {
            if (valid_oc[i]) {
                bias_val[i] = uBias.attr[oc_vec[i]];
            }
        }
        acc += bias_val;
    }

    // Activation
    acc = activation(acc, uConstant.activation);

    // Store output
    int out_y = n * H_out + h;
    imageStore(uOutput, ivec3(w, out_y, c4), acc);
}