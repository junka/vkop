// Prototype:
//  torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1)
//
// onnx:Conv
//  inputs: input, weight, bias(optional)
//  attributes:
//      strides: list of ints
//      pads: list of ints
//      dilations: list of ints
//      group: int
//      auto_pad: string, default ""
//  output: output
//  input shape: (N, C_in, H_in, W_in)  (NCHW)
//  weight shape: (C_out, C_in/groups, kH, kW)
//  bias shape: (C_out)
//  output shape: (N, C_out, H_out, W_out)
//      H_out = floor((H_in + 2*padding[0] - dilation[0]*(kH-1) - 1)/strides[0] + 1
//      W_out = floor((W_in + 2*padding[1] - dilation[1]*(kW-1) - 1)/strides[1] + 1
#version 450 core

#extension GL_AMD_gpu_shader_half_float: enable
#extension GL_EXT_shader_16bit_storage : enable
#ifdef FP16
#define FLOAT float16_t
#define FLOAT4 f16vec4
#else
#define FLOAT float
#define FLOAT4 vec4
#endif

#include "activation.comp"

layout(local_size_x = 16, local_size_y = 16, local_size_z = 1) in;

layout(set=0, binding=0) writeonly uniform image2DArray uOutput;   // [W_out, N*H_out, C4_out]
layout(set=0, binding=1) uniform sampler2DArray uInput;            // [W_in, N*H_in, C4_in]
layout(set=0, binding=2) uniform sampler2DArray uKernel;           // [K_W , K_H * C_out, UP_DIV(C_in/group, 4)] or transpose [K_W, K_H * C_in/groups, C4_out]
layout(set=0, binding=3) readonly buffer biasBuffer {
    uvec4 attr[];
} uBias;
layout(set=0, binding=4) readonly buffer bnBuffer {
    vec4 attr[];
} uBnPara;

layout(push_constant) uniform constBuffer {
    ivec4 inputSize;     // [W_in, H_in, C_in, N]
    ivec4 outputSize;    // [W_out, H_out, C_out, N]
    ivec4 kernelSize;    // [K_W, K_H, unused, unused]
    ivec2 stride;
    ivec2 padding;
    ivec2 dilation;
    int groups;
    int bias;
    int transpose;       // weight transpose Cin, Cout
    int pack;            // pack 1x1 weight to single layer image
    int activation;
    int fuse_bn;
    float eps;
    int fp16;
} uConstant;

vec4 batch_norm(vec4 value, int c4, bvec4 valid_oc)
{
    vec4 scale4 = uBnPara.attr[c4 * 4];
    vec4 bias4 = uBnPara.attr[c4 * 4 + 1];
    vec4 mean4 = uBnPara.attr[c4 * 4 + 2];
    vec4 var4 = uBnPara.attr[c4 * 4 + 3];

    // BatchNorm formula: y = scale * (x - mean) / sqrt(var + eps) + bias
    vec4 inv_std = inversesqrt(var4 + vec4(uConstant.eps));
    vec4 normalized = (value - mean4) * inv_std;
    vec4 ret = scale4 * normalized + bias4;
    return ret * vec4(valid_oc);
}

// support both fp16 and fp32 initializer
vec4 add_bias(vec4 value, int c4, bvec4 valid_oc) {
    vec4 bias_value = vec4(0.0);
    if (uConstant.fp16 != 0) {
        int gc4 = c4 / 2;
        int comp = c4 % 2;
        uvec4 packed_vec = uBias.attr[gc4];
        bias_value.xy = (unpackHalf2x16(packed_vec[2*comp]));
        bias_value.zw = (unpackHalf2x16(packed_vec[2*comp+1]));
    } else {
        bias_value = uintBitsToFloat(uBias.attr[c4]);
    }
    bias_value *= vec4(valid_oc);

    return value + bias_value;
}

void conv1x1() {
    ivec3 gid = ivec3(gl_GlobalInvocationID);
    ivec3 imgsz = imageSize(uOutput);
    int W_out = imgsz.x;
    int realH = imgsz.y;
    int C4_out = imgsz.z;

    if (gid.x >= W_out || gid.y >= realH || gid.z >= C4_out) return;

    int H_out = uConstant.outputSize.y;
    int C_out = uConstant.outputSize.z;
    int N = uConstant.outputSize.w;

    int W_in = uConstant.inputSize.x;
    int H_in = uConstant.inputSize.y;
    int C_in = uConstant.inputSize.z;
    int G = uConstant.groups;

    // Decode spatial and batch
    int w = gid.x;
    int c4 = gid.z;
    int n = gid.y / H_out;
    int h = gid.y % H_out;

    // For 1x1 conv with no padding/stride !=1, compute input position
    // But typically: stride=(1,1), padding=(0,0) → ix=w, iy=h
    int ix = w * uConstant.stride.x - uConstant.padding.x;
    int iy = h * uConstant.stride.y - uConstant.padding.y;

    // Early out if input pos is invalid (should not happen for valid 1x1)
    if (ix < 0 || ix >= W_in || iy < 0 || iy >= H_in) {
        imageStore(uOutput, gid, FLOAT4(0.0));
        return;
    }

    // Output channels handled by this thread
    int oc_start = c4 * 4;
    ivec4 oc_vec = oc_start + ivec4(0, 1, 2, 3);
    bvec4 valid_oc = lessThan(oc_vec, ivec4(C_out));

    int C_out_per_group = C_out / G;
    int C_in_per_group = C_in / G;

    bool full_vec4_valid = all(valid_oc);
    int g0 = oc_vec[0] / C_out_per_group;
    bool same_group = (g0 == (oc_vec[3] / C_out_per_group));
    bool can_vectorize_oc = full_vec4_valid && same_group;
    bool use_vec4 = (C_in_per_group % 4 == 0);
    int num_vec4 = (C_in_per_group + 3) / 4;

    FLOAT4 acc = FLOAT4(0.0);
    int in_y = n * H_in + iy;

    // ————————————————————————
    // 1x1 Conv: no spatial loop
    // ————————————————————————
    if (uConstant.transpose == 0) {
        if (can_vectorize_oc) {
            int ic_start = g0 * C_in_per_group;
            int ic_end = ic_start + C_in_per_group;
            FLOAT4 acc_local = FLOAT4(0.0);

            if (use_vec4) {
                for (int v = 0; v < num_vec4; ++v) {
                    int global_ic = ic_start + v * 4;
                    int input_layer = global_ic / 4;
                    // ic4
                    FLOAT4 x_vec = texelFetch(uInput, ivec3(ix, in_y, input_layer), 0);

                    // Kernel: stored as [ic4, oc], layer=0
                    // Fetch weight for each of the 4 output channels
                    // ic4, oc [0, 1, 2, 3}
                    FLOAT4 w0 = texelFetch(uKernel, ivec3(v, oc_vec[0], 0), 0);
                    FLOAT4 w1 = texelFetch(uKernel, ivec3(v, oc_vec[1], 0), 0);
                    FLOAT4 w2 = texelFetch(uKernel, ivec3(v, oc_vec[2], 0), 0);
                    FLOAT4 w3 = texelFetch(uKernel, ivec3(v, oc_vec[3], 0), 0);

                    acc_local.x += dot(x_vec, w0);
                    acc_local.y += dot(x_vec, w1);
                    acc_local.z += dot(x_vec, w2);
                    acc_local.w += dot(x_vec, w3);
                }
            } else {
                for (int ic = ic_start; ic < ic_end; ++ic) {
                    int input_layer = ic / 4;
                    int input_comp = ic % 4;
                    FLOAT x = texelFetch(uInput, ivec3(ix, in_y, input_layer), 0)[input_comp];

                    int local_ic = ic - ic_start;
                    int kernel_layer = local_ic / 4;
                    int kernel_comp = local_ic % 4;

                    // Kernel: stored as [ic4, oc], layer=0
                    // Fetch weight for each of the 4 output channels
                    FLOAT4 w_vec;
                    w_vec.x = texelFetch(uKernel, ivec3(kernel_layer, oc_vec[0], 0), 0)[kernel_comp];
                    w_vec.y = texelFetch(uKernel, ivec3(kernel_layer, oc_vec[1], 0), 0)[kernel_comp];
                    w_vec.z = texelFetch(uKernel, ivec3(kernel_layer, oc_vec[2], 0), 0)[kernel_comp];
                    w_vec.w = texelFetch(uKernel, ivec3(kernel_layer, oc_vec[3], 0), 0)[kernel_comp];

                    acc_local += x * w_vec;
                }
            }
            acc = acc_local;
        } else {
            // Handle each output channel individually
            for (int comp = 0; comp < 4; ++comp) {
                if (!valid_oc[comp]) continue;

                int oc = oc_vec[comp];
                int g = oc / C_out_per_group;
                int ic_start = g * C_in_per_group;
                FLOAT sum = FLOAT(0.0);

                if (use_vec4) {
                    for (int v = 0; v < num_vec4; ++v) {
                        int global_ic = ic_start + v * 4;
                        int input_layer = global_ic / 4;
                        FLOAT4 x_vec = texelFetch(uInput, ivec3(ix, in_y, input_layer), 0);
                        FLOAT4 w_vec = texelFetch(uKernel, ivec3(v, oc, 0), 0);
                        sum += dot(x_vec, w_vec);
                    }
                } else {
                    for (int ic = ic_start; ic < ic_start + C_in_per_group; ++ic) {
                        int input_layer = ic / 4;
                        int input_comp = ic % 4;
                        FLOAT x = texelFetch(uInput, ivec3(ix, in_y, input_layer), 0)[input_comp];

                        int local_ic = ic - ic_start;
                        int kernel_layer = local_ic / 4;
                        int kernel_comp = local_ic % 4;

                        FLOAT w = texelFetch(uKernel, ivec3(kernel_layer, oc, 0), 0)[kernel_comp];
                        sum += x * w;
                    }
                }
                acc[comp] = sum;
            }
        }
    } else {
        if (can_vectorize_oc) {
            int ic_start = g0 * C_in_per_group;
            int ic_end = ic_start + C_in_per_group;
            FLOAT4 acc_local = FLOAT4(0.0);

            if (use_vec4) {
                // Vectorize over input channels and output channels, oc4, ic4
                for (int v = 0; v < num_vec4; ++v) {
                    int global_ic = ic_start + v * 4;
                    int input_layer = global_ic / 4;
                    // ic4
                    FLOAT4 x_vec = texelFetch(uInput, ivec3(ix, in_y, input_layer), 0);

                    // Kernel: stored as [oc4, ic], layer=0
                    // Fetch weight for each of the 4 output channels
                    int local_ic = global_ic - ic_start;
                    FLOAT4 w0 = texelFetch(uKernel, ivec3(c4, local_ic, 0), 0);   // oc4, ic
                    FLOAT4 w1 = texelFetch(uKernel, ivec3(c4, local_ic+1, 0), 0); // oc4, ic+1
                    FLOAT4 w2 = texelFetch(uKernel, ivec3(c4, local_ic+2, 0), 0); // oc4, ic+2
                    FLOAT4 w3 = texelFetch(uKernel, ivec3(c4, local_ic+3, 0), 0); // oc4, ic+3

                    acc_local += x_vec.x * w0;
                    acc_local += x_vec.y * w1;
                    acc_local += x_vec.z * w2;
                    acc_local += x_vec.w * w3;
                }
            } else {
                // Handle each output channel individually (oc4, ic)
                for (int ic = ic_start; ic < ic_end; ++ic) {
                    int input_layer = ic / 4;
                    int input_comp = ic % 4;
                    FLOAT x = texelFetch(uInput, ivec3(ix, in_y, input_layer), 0)[input_comp];

                    int local_ic = ic - ic_start;
                    // Kernel: stored as [oc4, ic], layer=0
                    // Fetch weight for each of the 4 output channels
                    FLOAT4 w_vec = texelFetch(uKernel, ivec3(c4, local_ic, 0), 0); // oc4, ic

                    acc_local += x * w_vec;
                }
            }
            acc = acc_local;
        } else {
            // Handle each output channel individually
            for (int comp = 0; comp < 4; ++comp) {
                if (!valid_oc[comp]) continue;

                int oc = oc_vec[comp];
                int g = oc / C_out_per_group;
                int ic_start = g * C_in_per_group;
                FLOAT sum = FLOAT(0.0);

                if (use_vec4) {
                    // vector path, fetch each weight(oc, ic4) * input(ic4)
                    for (int v = 0; v < num_vec4; ++v) {
                        int global_ic = ic_start + v * 4;
                        int input_layer = global_ic / 4;
                        FLOAT4 x_vec = texelFetch(uInput, ivec3(ix, in_y, input_layer), 0);
                        FLOAT4 w_vec;
                        int local_ic = global_ic - ic_start;
                        w_vec.x = texelFetch(uKernel, ivec3(c4, local_ic, 0), 0)[comp];
                        w_vec.y = texelFetch(uKernel, ivec3(c4, local_ic + 1, 0), 0)[comp];
                        w_vec.z = texelFetch(uKernel, ivec3(c4, local_ic + 2, 0), 0)[comp];
                        w_vec.w = texelFetch(uKernel, ivec3(c4, local_ic + 3, 0), 0)[comp];
                        sum += dot(x_vec, w_vec);
                    }
                } else {
                    // most scalar path, fetch each wieght(oc, ic) * input(ic)
                    for (int ic = ic_start; ic < ic_start + C_in_per_group; ++ic) {
                        int input_layer = ic / 4;
                        int input_comp = ic % 4;
                        FLOAT x = texelFetch(uInput, ivec3(ix, in_y, input_layer), 0)[input_comp];

                        int local_ic = ic - ic_start;
                        FLOAT w = texelFetch(uKernel, ivec3(c4, local_ic, 0), 0)[comp];
                        sum += x * w;
                    }
                }
                acc[comp] = sum;
            }
        }
    }

    if (uConstant.bias != 0) {
        acc = add_bias(acc, c4, valid_oc);
    }
    if (uConstant.fuse_bn != 0) {
        acc = batch_norm(acc, c4, valid_oc);
    }

    acc = activation(acc, uConstant.activation);

    imageStore(uOutput, gid, acc);

}

void grouped_conv2d() {
    ivec3 gid = ivec3(gl_GlobalInvocationID);
    ivec3 imgsz = imageSize(uOutput);
    int W_out = imgsz.x;
    int realH = imgsz.y;
    int C4_out = imgsz.z;

    if (gid.x >= W_out || gid.y >= realH || gid.z >= C4_out) return;

    int H_out = uConstant.outputSize.y;
    int C_out = uConstant.outputSize.z;
    int N = uConstant.outputSize.w;

    int W_in = uConstant.inputSize.x;
    int H_in = uConstant.inputSize.y;
    int C_in = uConstant.inputSize.z;
    int G = uConstant.groups;

    // Decode spatial and channel
    int w = gid.x;
    int c4 = gid.z;
    int n = gid.y / H_out;
    int h = gid.y % H_out;

    // Output channel start
    int oc_start = c4 * 4;
    ivec4 oc_vec = oc_start + ivec4(0, 1, 2, 3);
    bvec4 valid_oc = lessThan(oc_vec, ivec4(C_out));

    // Compute input start position (with padding)
    ivec2 out_pos = ivec2(w, h);
    ivec2 s0 = out_pos * uConstant.stride - uConstant.padding;

    FLOAT4 acc = FLOAT4(0.0);

    int K_W = uConstant.kernelSize.x;
    int K_H = uConstant.kernelSize.y;
    int C_out_per_group = C_out / G;
    int C_in_per_group = C_in / G;
    bool full_vec4_valid = all(valid_oc);
    int g0 = oc_vec[0] / C_out_per_group;
    bool same_group = (g0 == (oc_vec[3] / C_out_per_group));
    bool can_vectorize_oc = full_vec4_valid && same_group;
    bool use_vec4 = (C_in_per_group % 4 == 0);
    int num_vec4 = (C_in_per_group + 3) / 4;

    if (uConstant.transpose == 1) {
        if (can_vectorize_oc) {
            int ic_start = g0 * C_in_per_group;
            int ic_end = ic_start + C_in_per_group;
            FLOAT4 acc_local = FLOAT4(0.0);

            for (int ky = 0; ky < K_H; ++ky) {
                int iy = s0.y + ky * uConstant.dilation.y;
                if (iy < 0 || iy >= H_in) continue;

                for (int kx = 0; kx < K_W; ++kx) {
                    int ix = s0.x + kx * uConstant.dilation.x;
                    if (ix < 0 || ix >= W_in) continue;
                    if (use_vec4) {
                        for (int v = 0; v < num_vec4; ++v) {
                            int global_ic0 = ic_start + v * 4;
                            int input_layer = global_ic0 / 4;
                            int in_y = n * H_in + iy;

                            FLOAT4 x_vec = texelFetch(uInput, ivec3(ix, in_y, input_layer), 0); // ic4

                            int local_ic = global_ic0 - ic_start;
                            // Each output channel has its own row in Y, same layer c4
                            FLOAT4 w0 = texelFetch(uKernel, ivec3(kx, ky + local_ic * K_H, c4), 0);
                            FLOAT4 w1 = texelFetch(uKernel, ivec3(kx, ky + (local_ic + 1) * K_H, c4), 0);
                            FLOAT4 w2 = texelFetch(uKernel, ivec3(kx, ky + (local_ic + 2) * K_H, c4), 0);
                            FLOAT4 w3 = texelFetch(uKernel, ivec3(kx, ky + (local_ic + 3) * K_H, c4), 0);

                            acc_local += x_vec.x * w0;
                            acc_local += x_vec.y * w1;
                            acc_local += x_vec.z * w2;
                            acc_local += x_vec.w * w3;
                        }
                    } else {
                        for (int ic = ic_start; ic < ic_end; ++ic) {
                            int input_layer = ic / 4;
                            int input_comp = ic % 4;
                            int in_y = n * H_in + iy;
                            FLOAT x = texelFetch(uInput, ivec3(ix, in_y, input_layer), 0)[input_comp];

                            int local_ic = ic - ic_start;

                            FLOAT4 w_vec = texelFetch(uKernel, ivec3(kx, ky + local_ic * K_H, c4), 0);

                            acc_local += x * w_vec;
                        }
                    }
                }
            }
            acc = acc_local;
        } else {
            for (int comp = 0; comp < 4; ++comp) {
                if (!valid_oc[comp]) continue;
                int oc = oc_vec[comp];
                int g = oc / C_out_per_group;
                int ic_start = g * C_in_per_group;
                int ic_end = ic_start + C_in_per_group;
                FLOAT sum = FLOAT(0.0);

                for (int ky = 0; ky < K_H; ++ky) {
                    int iy = s0.y + ky * uConstant.dilation.y;
                    if (iy < 0 || iy >= H_in) continue;
                    for (int kx = 0; kx < K_W; ++kx) {
                        int ix = s0.x + kx * uConstant.dilation.x;
                        if (ix < 0 || ix >= W_in) continue;

                        for (int ci = ic_start; ci < ic_end; ++ci) {
                            int in_y = n * H_in + iy;
                            int global_ci4 = ci / 4;
                            int global_ci_comp = ci % 4;
                            FLOAT x = texelFetch(uInput, ivec3(ix, in_y, global_ci4), 0)[global_ci_comp];

                            int local_ci = ci - ic_start;
                            int kernel_comp = oc % 4;
                            FLOAT w = texelFetch(uKernel, ivec3(kx, ky + local_ci * K_H, c4), 0)[kernel_comp];

                            sum += x * w;
                        }
                    }
                }
                acc[comp] = sum;
            }
        }
    } else {
        if (can_vectorize_oc) {
            int ic_start = g0 * C_in_per_group;
            int ic_end = ic_start + C_in_per_group;

            FLOAT4 acc_local = FLOAT4(0.0);

            for (int ky = 0; ky < K_H; ++ky) {
                int iy = s0.y + ky * uConstant.dilation.y;
                if (iy < 0 || iy >= H_in) continue;

                for (int kx = 0; kx < K_W; ++kx) {
                    int ix = s0.x + kx * uConstant.dilation.x;
                    if (ix < 0 || ix >= W_in) continue;

                    if (use_vec4) {
                        // Vec4 over input channels AND output channels
                        for (int v = 0; v < num_vec4; ++v) {
                            int global_ic0 = ic_start + v * 4;
                            int input_layer = global_ic0 / 4;
                            int in_y = n * H_in + iy;
                            FLOAT4 x_vec = texelFetch(uInput, ivec3(ix, in_y, input_layer), 0);

                            // Fetch 4 weights for 4 output channels at once!
                            // Each oc has its own row in kernel texture
                            FLOAT4 w0 = texelFetch(uKernel, ivec3(kx, ky + oc_vec[0] * K_H, v), 0);
                            FLOAT4 w1 = texelFetch(uKernel, ivec3(kx, ky + oc_vec[1] * K_H, v), 0);
                            FLOAT4 w2 = texelFetch(uKernel, ivec3(kx, ky + oc_vec[2] * K_H, v), 0);
                            FLOAT4 w3 = texelFetch(uKernel, ivec3(kx, ky + oc_vec[3] * K_H, v), 0);

                            // Broadcast x_vec and multiply per-output-channel weights
                            acc_local.x += dot(x_vec, w0);
                            acc_local.y += dot(x_vec, w1);
                            acc_local.z += dot(x_vec, w2);
                            acc_local.w += dot(x_vec, w3);
                        }
                    } else {
                        // Scalar input channels, but vectorized over output
                        for (int ic = ic_start; ic < ic_end; ++ic) {
                            int input_layer = ic / 4;
                            int input_comp = ic % 4;
                            int in_y = n * H_in + iy;
                            FLOAT x = texelFetch(uInput, ivec3(ix, in_y, input_layer), 0)[input_comp];

                            int local_ic = ic - ic_start;
                            int kernel_layer = local_ic / 4;
                            int kernel_comp = local_ic % 4;

                            FLOAT4 w_vec;
                            w_vec.x = texelFetch(uKernel, ivec3(kx, ky + oc_vec[0] * K_H, kernel_layer), 0)[kernel_comp];
                            w_vec.y = texelFetch(uKernel, ivec3(kx, ky + oc_vec[1] * K_H, kernel_layer), 0)[kernel_comp];
                            w_vec.z = texelFetch(uKernel, ivec3(kx, ky + oc_vec[2] * K_H, kernel_layer), 0)[kernel_comp];
                            w_vec.w = texelFetch(uKernel, ivec3(kx, ky + oc_vec[3] * K_H, kernel_layer), 0)[kernel_comp];

                            acc_local += x * w_vec;
                        }
                    }
                }
            }
            acc = acc_local;

        } else {
            // For each output channel in this vec4
            for (int comp = 0; comp < 4; ++comp) {
                if (!valid_oc[comp]) continue;

                int oc = oc_vec[comp];
                int g = oc / C_out_per_group; // which group?

                // Input channel range for this group
                int ic_start = g * C_in_per_group;
                int ic_end = ic_start + C_in_per_group;

                FLOAT sum = FLOAT(0.0);

                for (int ky = 0; ky < K_H; ++ky) {
                    int iy = s0.y + ky * uConstant.dilation.y;
                    if (iy < 0 || iy >= H_in) continue;

                    for (int kx = 0; kx < K_W; ++kx) {
                        int ix = s0.x + kx * uConstant.dilation.x;
                        if (ix < 0 || ix >= W_in) continue;

                        if (use_vec4) {
                            FLOAT4 sum4 = FLOAT4(0.0);
                            for (int v = 0; v < num_vec4; ++v) {
                                // Global input layer for channels [ic_start + v*4, ...)
                                int global_ic0 = ic_start + v * 4;
                                int input_layer = global_ic0 / 4; // safe because aligned

                                int in_y = n * H_in + iy;
                                FLOAT4 x_vec = texelFetch(uInput, ivec3(ix, in_y, input_layer), 0);
                                FLOAT4 w_vec = texelFetch(uKernel, ivec3(kx, ky + oc * K_H, v), 0);
                                sum4 += x_vec * w_vec;
                            }
                            sum += dot(sum4, vec4(1.0));
                        } else {
                            // Iterate over input channels in this group
                            for (int ic = ic_start; ic < ic_end; ++ic) {
                                int ic4 = ic / 4;
                                int ic_comp = ic % 4;

                                // Fetch input pixel
                                int in_y = n * H_in + iy;
                                FLOAT input_val = FLOAT4(texelFetch(uInput, ivec3(ix, in_y, ic4), 0))[ic_comp];

                                // Compute kernel coordinate
                                int local_ic = ic - ic_start; // local within group
                                int local_ic4 = local_ic / 4;
                                int local_ic_comp = local_ic % 4;

                                int kx_k = kx;
                                int ky_k = ky + oc * K_H;
                                FLOAT4 weight_vec = texelFetch(uKernel, ivec3(kx_k, ky_k, local_ic4), 0);
                                FLOAT w = weight_vec[local_ic_comp];

                                sum += input_val * w;
                            }
                        }
                    }
                }
                acc[comp] = sum;
            }
        }
    }

    if (uConstant.bias != 0) {
        acc = add_bias(acc, c4, valid_oc);
    }

    if (uConstant.fuse_bn != 0) {
        acc = batch_norm(acc, c4, valid_oc);
    }

    acc = activation(acc, uConstant.activation);

    imageStore(uOutput, gid, acc);
}


void main() {

    if (uConstant.pack == 1) {
        conv1x1();
    } else {
        grouped_conv2d();
    }
}